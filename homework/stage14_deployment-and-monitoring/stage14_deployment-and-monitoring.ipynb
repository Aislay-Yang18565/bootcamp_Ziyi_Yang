{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7cc3172",
   "metadata": {},
   "source": [
    "# Homework Starter — Stage 14: Deployment & Monitoring\n",
    "\n",
    "Use this template to draft your reflection and (optionally) sketch a dashboard."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d82d80",
   "metadata": {},
   "source": [
    "## 1) Reflection (200–300 words)\n",
    "Deploying a predictive model in production introduces multiple risks. First, data pipelines may suffer schema drift or delayed updates, which could silently break feature quality. Second, input distributions may shift, making the trained model less accurate over time. Third, system infrastructure could degrade under higher load, causing increased latency or failures. Finally, misalignment between predictions and business outcomes could erode stakeholder trust if not detected quickly.\n",
    "\n",
    "To address these, monitoring must span four layers. Data: track schema hash changes, percentage of null values, and population stability index (PSI), alerting if PSI exceeds 5% on key features. Model: log rolling accuracy and AUC weekly, and flag when AUC falls below 0.65 over a two-week window. System: record job success rate and p95 latency, with alerts if latency exceeds 500 ms or success falls below 99%. Business: monitor downstream KPIs such as approval rate or revenue lift, with thresholds aligned to baseline performance. Each alert should have a runbook starting with data validation checks before escalation.\n",
    "\n",
    "Ownership must also be explicit. Data engineers handle schema and freshness issues, while the ML team owns retraining and model performance dashboards. The platform on-call team maintains system reliability, and business analysts review KPI dashboards weekly. Handoffs occur via tickets in the tracking system, with rollback authority resting with the ML lead. This layered and role-based plan ensures sustainable operations and transparent accountability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc7436e",
   "metadata": {},
   "source": [
    "## 2) Optional: Dashboard Sketch\n",
    "Describe panels and key charts. You can also attach an image file in your repo (png/pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d60337f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': ['freshness_minutes', 'null_rate', 'schema_hash'],\n",
       " 'model': ['rolling_mae_or_auc', 'calibration_error'],\n",
       " 'system': ['p95_latency_ms', 'error_rate'],\n",
       " 'business': ['approval_rate', 'bad_rate']}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optional helper: simple structure to list metrics\n",
    "monitoring = {\n",
    "    'data': ['freshness_minutes', 'null_rate', 'schema_hash'],\n",
    "    'model': ['rolling_mae_or_auc', 'calibration_error'],\n",
    "    'system': ['p95_latency_ms', 'error_rate'],\n",
    "    'business': ['approval_rate', 'bad_rate']\n",
    "}\n",
    "monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cda558-b461-4598-9c48-8742c572dd27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
