{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26a2501b-fe5f-47f5-831b-28252ea43e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching TSLA data for 3mo period...\n",
      "Data successfully saved to:\n",
      "C:\\Users\\Aislay\\bootcamp_Ziyi_Yang\\homework\\stage04_data-acquisition-and-ingestion\\data\\raw\\api_yfinance_TSLA_20250822-2102.csv\n",
      "\n",
      "Data Preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjusted_close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-05-23</td>\n",
       "      <td>337.920013</td>\n",
       "      <td>343.179993</td>\n",
       "      <td>333.209991</td>\n",
       "      <td>339.339996</td>\n",
       "      <td>339.339996</td>\n",
       "      <td>84654800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-05-27</td>\n",
       "      <td>347.350006</td>\n",
       "      <td>363.790009</td>\n",
       "      <td>347.320007</td>\n",
       "      <td>362.890015</td>\n",
       "      <td>362.890015</td>\n",
       "      <td>120146400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-05-28</td>\n",
       "      <td>364.839996</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>355.910004</td>\n",
       "      <td>356.899994</td>\n",
       "      <td>356.899994</td>\n",
       "      <td>91404300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-05-29</td>\n",
       "      <td>365.290009</td>\n",
       "      <td>367.709991</td>\n",
       "      <td>356.000000</td>\n",
       "      <td>358.429993</td>\n",
       "      <td>358.429993</td>\n",
       "      <td>88087800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-05-30</td>\n",
       "      <td>355.519989</td>\n",
       "      <td>363.679993</td>\n",
       "      <td>345.290009</td>\n",
       "      <td>346.459991</td>\n",
       "      <td>346.459991</td>\n",
       "      <td>123474900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date        open        high         low       close  adjusted_close  \\\n",
       "0 2025-05-23  337.920013  343.179993  333.209991  339.339996      339.339996   \n",
       "1 2025-05-27  347.350006  363.790009  347.320007  362.890015      362.890015   \n",
       "2 2025-05-28  364.839996  365.000000  355.910004  356.899994      356.899994   \n",
       "3 2025-05-29  365.290009  367.709991  356.000000  358.429993      358.429993   \n",
       "4 2025-05-30  355.519989  363.679993  345.290009  346.459991      346.459991   \n",
       "\n",
       "      volume  \n",
       "0   84654800  \n",
       "1  120146400  \n",
       "2   91404300  \n",
       "3   88087800  \n",
       "4  123474900  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Robust Stock Data Fetcher\n",
    "-------------------------\n",
    "Fetches historical stock data from Yahoo Finance, standardizes the format,\n",
    "validates data quality, and saves to CSV with timestamp.\n",
    "\"\"\"\n",
    "\n",
    "# Standard Library Imports\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Third-Party Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "# ======================\n",
    "# CONFIGURATION SETTINGS\n",
    "# ======================\n",
    "DATA_PATH = Path(\"C:/Users/Aislay/bootcamp_Ziyi_Yang/homework/stage04_data-acquisition-and-ingestion/data/raw\")\n",
    "TICKER = \"TSLA\"  # Tesla stock symbol\n",
    "PERIOD = \"3mo\"   # 3 months historical data\n",
    "INTERVAL = \"1d\"  # Daily intervals\n",
    "\n",
    "# =================\n",
    "# CORE FUNCTIONS\n",
    "# =================\n",
    "\n",
    "def initialize_environment():\n",
    "    \"\"\"Ensure data directory exists\"\"\"\n",
    "    DATA_PATH.mkdir(parents=True, exist_ok=True)\n",
    "    return datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "\n",
    "def fetch_stock_data(ticker, period, interval):\n",
    "    \"\"\"Download stock data from Yahoo Finance\"\"\"\n",
    "    print(f\"Fetching {ticker} data for {period} period...\")\n",
    "    df = yf.download(\n",
    "        ticker, \n",
    "        period=period,\n",
    "        interval=interval,\n",
    "        auto_adjust=False,\n",
    "        progress=False\n",
    "    )\n",
    "    \n",
    "    if df is None or len(df) == 0:\n",
    "        raise RuntimeError(\"Failed to download data (check network/ticker).\")\n",
    "    return df\n",
    "\n",
    "def standardize_data(df):\n",
    "    \"\"\"Normalize dataframe structure and columns\"\"\"\n",
    "    # Flatten MultiIndex columns if present\n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        df.columns = [c[0] for c in df.columns]\n",
    "    \n",
    "    # Reset index and clean column names\n",
    "    df = df.reset_index()\n",
    "    df.columns = [str(c).strip().lower() for c in df.columns]\n",
    "    \n",
    "    # Standardize date column name\n",
    "    date_col = next(\n",
    "        (c for c in [\"date\", \"datetime\", \"index\"] if c in df.columns),\n",
    "        df.columns[0]\n",
    "    )\n",
    "    df = df.rename(columns={date_col: \"date\"})\n",
    "    \n",
    "    # Standardize adjusted close column names\n",
    "    rename_rules = {\n",
    "        \"adj close\": \"adjusted_close\",\n",
    "        \"adj_close\": \"adjusted_close\",\n",
    "        \"adjusted close\": \"adjusted_close\"\n",
    "    }\n",
    "    df = df.rename(columns={\n",
    "        k: v for k, v in rename_rules.items() \n",
    "        if k in df.columns\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "def validate_data(df):\n",
    "    \"\"\"Ensure required columns exist with proper data types\"\"\"\n",
    "    required_cols = [\n",
    "        \"date\", \"open\", \"high\", \"low\", \n",
    "        \"close\", \"adjusted_close\", \"volume\"\n",
    "    ]\n",
    "    \n",
    "    # Add missing columns with NaN values\n",
    "    for col in required_cols:\n",
    "        if col not in df.columns:\n",
    "            df[col] = np.nan\n",
    "    \n",
    "    # Convert data types\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "    numeric_cols = [\"open\", \"high\", \"low\", \"close\", \"adjusted_close\", \"volume\"]\n",
    "    for col in numeric_cols:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    \n",
    "    return df[required_cols].copy()\n",
    "\n",
    "def save_dataset(df, ticker, timestamp):\n",
    "    \"\"\"Save processed data to CSV\"\"\"\n",
    "    filename = f\"api_yfinance_{ticker}_{timestamp}.csv\"\n",
    "    outpath = DATA_PATH / filename\n",
    "    df.to_csv(outpath, index=False)\n",
    "    print(f\"Data successfully saved to:\\n{outpath}\")\n",
    "    return outpath\n",
    "\n",
    "# =================\n",
    "# MAIN EXECUTION\n",
    "# =================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Initialize\n",
    "        timestamp = initialize_environment()\n",
    "        \n",
    "        # Extract\n",
    "        raw_data = fetch_stock_data(TICKER, PERIOD, INTERVAL)\n",
    "        \n",
    "        # Transform\n",
    "        standardized_data = standardize_data(raw_data)\n",
    "        validated_data = validate_data(standardized_data)\n",
    "        \n",
    "        # Load\n",
    "        output_path = save_dataset(validated_data, TICKER, timestamp)\n",
    "        \n",
    "        # Preview\n",
    "        print(\"\\nData Preview:\")\n",
    "        display(validated_data.head())\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError occurred: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27153649-9c00-442c-a4bf-c9287087f213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping financial companies webpage: https://en.wikipedia.org/wiki/List_of_largest_financial_services_companies_by_revenue\n",
      "Successfully found financial companies table, parsing...\n",
      "\n",
      "=== Data Validation ===\n",
      "\n",
      "Cleaned column names: ['rank', 'company', 'industry', 'revenue_(usd_millions)', 'net_income_(usd_millions)', 'total_assets_(usd_billions)', 'headquarters']\n",
      "Error converting column revenue_(usd_millions): 'numpy.int64' object has no attribute 'lower'\n",
      "Error converting column total_assets_(usd_billions): 'numpy.int64' object has no attribute 'lower'\n",
      "\n",
      "Converted financial numeric columns: ['revenue_(usd_millions)', 'total_assets_(usd_billions)']\n",
      "\n",
      "NA values per column:\n",
      "rank                           0\n",
      "company                        0\n",
      "industry                       0\n",
      "revenue_(usd_millions)         0\n",
      "net_income_(usd_millions)      0\n",
      "total_assets_(usd_billions)    0\n",
      "headquarters                   0\n",
      "dtype: int64\n",
      "\n",
      "Final data shape: (52, 7)\n",
      "\n",
      "=== Scraping Results ===\n",
      "Successfully saved to: C:\\Users\\Aislay\\bootcamp_Ziyi_Yang\\homework\\homework4\\data\\raw\\scrape_wikipedia_financial_20250822-2102.csv\n",
      "Contains 52 financial companies records\n",
      "Financial sector distribution:\n",
      "No sector classification generated\n",
      "\n",
      "Data preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>company</th>\n",
       "      <th>industry</th>\n",
       "      <th>revenue_(usd_millions)</th>\n",
       "      <th>net_income_(usd_millions)</th>\n",
       "      <th>total_assets_(usd_billions)</th>\n",
       "      <th>headquarters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Transamerica Corporation</td>\n",
       "      <td>Insurance</td>\n",
       "      <td>245510</td>\n",
       "      <td>42,521</td>\n",
       "      <td>873</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ping An Insurance Group</td>\n",
       "      <td>Insurance</td>\n",
       "      <td>191509</td>\n",
       "      <td>20,738</td>\n",
       "      <td>1460</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ICBC</td>\n",
       "      <td>Banking</td>\n",
       "      <td>182794</td>\n",
       "      <td>45,783</td>\n",
       "      <td>5110</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>China Construction Bank</td>\n",
       "      <td>Banking</td>\n",
       "      <td>172000</td>\n",
       "      <td>39,282</td>\n",
       "      <td>4311</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Agricultural Bank of China</td>\n",
       "      <td>Banking</td>\n",
       "      <td>153884</td>\n",
       "      <td>31,293</td>\n",
       "      <td>4169</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  rank                     company   industry  revenue_(usd_millions)  \\\n",
       "0    1    Transamerica Corporation  Insurance                  245510   \n",
       "1    2     Ping An Insurance Group  Insurance                  191509   \n",
       "2    3                        ICBC    Banking                  182794   \n",
       "3    4     China Construction Bank    Banking                  172000   \n",
       "4    5  Agricultural Bank of China    Banking                  153884   \n",
       "\n",
       "  net_income_(usd_millions)  total_assets_(usd_billions)   headquarters  \n",
       "0                    42,521                          873  United States  \n",
       "1                    20,738                         1460          China  \n",
       "2                    45,783                         5110          China  \n",
       "3                    39,282                         4311          China  \n",
       "4                    31,293                         4169          China  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Complete Web Scraping Code for Financial Companies Data\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from IPython.display import display\n",
    "\n",
    "# 1. Setup Paths and Parameters\n",
    "# --------------------------------------------------\n",
    "# Specify custom save path (modify according to your actual path)\n",
    "CUSTOM_PATH = Path(\"C:/Users/Aislay/bootcamp_Ziyi_Yang/homework/homework4/data/raw\")\n",
    "CUSTOM_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Generate timestamp automatically\n",
    "STAMP = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "\n",
    "# 2. Select Target Webpage (Financial Companies List)\n",
    "# --------------------------------------------------\n",
    "URL = \"https://en.wikipedia.org/wiki/List_of_largest_financial_services_companies_by_revenue\"\n",
    "HEADERS = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "# 3. Web Scraping and Table Parsing\n",
    "# --------------------------------------------------\n",
    "try:\n",
    "    print(f\"Scraping financial companies webpage: {URL}\")\n",
    "    \n",
    "    # Send HTTP request\n",
    "    response = requests.get(URL, headers=HEADERS, timeout=15)\n",
    "    response.raise_for_status()  # Check for HTTP errors\n",
    "    \n",
    "    # Parse HTML with BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Find target table (select table containing financial companies data)\n",
    "    # This page has multiple tables, we select the first complete data table\n",
    "    target_tables = soup.find_all('table', {'class': 'wikitable'})\n",
    "    if not target_tables:\n",
    "        raise ValueError(\"No qualified table found on the page\")\n",
    "    \n",
    "    # Typically the first table is the main data table\n",
    "    table = target_tables[0]\n",
    "    print(\"Successfully found financial companies table, parsing...\")\n",
    "    \n",
    "    # Extract table headers\n",
    "    headers = []\n",
    "    for th in table.find('tr').find_all('th'):  # First row contains headers\n",
    "        header_text = th.text.strip()\n",
    "        # Clean special characters and line breaks\n",
    "        header_text = re.sub(r'[\\n\\r]+', ' ', header_text)\n",
    "        headers.append(header_text)\n",
    "    \n",
    "    # Extract table data\n",
    "    table_data = []\n",
    "    for row in table.find_all('tr')[1:]:  # Skip header row\n",
    "        row_data = []\n",
    "        for cell in row.find_all(['th', 'td']):\n",
    "            cell_text = cell.text.strip()\n",
    "            # Clean special characters and line breaks\n",
    "            cell_text = re.sub(r'[\\n\\r]+', ' ', cell_text)\n",
    "            row_data.append(cell_text)\n",
    "        if row_data:  # Ignore empty rows\n",
    "            table_data.append(row_data)\n",
    "    \n",
    "    # 4. Create DataFrame\n",
    "    # --------------------------------------------------\n",
    "    df = pd.DataFrame(table_data, columns=headers)\n",
    "    \n",
    "    # 5. Data Cleaning and Validation (Optimized for Financial Data)\n",
    "    # --------------------------------------------------\n",
    "    print(\"\\n=== Data Validation ===\")\n",
    "    \n",
    "    # Clean column names\n",
    "    df.columns = [col.lower().replace(' ', '_').replace('.', '') for col in df.columns]\n",
    "    print(f\"\\nCleaned column names: {df.columns.tolist()}\")\n",
    "    \n",
    "    # Financial-specific cleaning\n",
    "    # Ensure company name column exists\n",
    "    if 'company' not in df.columns and 'name' not in df.columns:\n",
    "        # Try to identify company name column\n",
    "        company_col = next((col for col in df.columns if 'company' in col or 'name' in col), df.columns[0])\n",
    "        df = df.rename(columns={company_col: 'company'})\n",
    "    \n",
    "    # Identify and convert numeric columns (financial-specific fields)\n",
    "    numeric_cols = []\n",
    "    financial_keywords = ['revenue', 'assets', 'profit', 'market_cap', 'capitalization']\n",
    "    \n",
    "    for col in df.columns:\n",
    "        # Financial numeric fields processing\n",
    "        if any(keyword in col for keyword in financial_keywords):\n",
    "            try:\n",
    "                # Remove currency symbols, units (B,M), thousand separators etc.\n",
    "                temp_series = df[col].str.replace(r'[^\\d.-]', '', regex=True)\n",
    "                temp_series = pd.to_numeric(temp_series, errors='coerce')\n",
    "                if not temp_series.isna().all():  # Only keep if conversion is successful\n",
    "                    df[col] = temp_series\n",
    "                    numeric_cols.append(col)\n",
    "                    # Add unit conversion note (e.g., B for billion)\n",
    "                    if 'b' in df[col].iloc[0].lower() if pd.notna(df[col].iloc[0]) else False:\n",
    "                        df[col] = df[col] * 1e9  # Assuming B stands for billion\n",
    "            except Exception as e:\n",
    "                print(f\"Error converting column {col}: {str(e)}\")\n",
    "                pass\n",
    "    \n",
    "    print(f\"\\nConverted financial numeric columns: {numeric_cols}\")\n",
    "    \n",
    "    # Financial sector classification\n",
    "    if 'industry' not in df.columns and 'sector' not in df.columns:\n",
    "        # Try to identify financial subsectors from company names or descriptions\n",
    "        df['financial_sector'] = 'Other Financial'\n",
    "        bank_keywords = ['bank', 'banc', 'credit']\n",
    "        insurance_keywords = ['insurance', 'assurance', 'reinsurance']\n",
    "        investment_keywords = ['investment', 'asset management', 'capital', 'brokerage']\n",
    "        \n",
    "        def classify_sector(name):\n",
    "            name = str(name).lower()\n",
    "            if any(keyword in name for keyword in bank_keywords):\n",
    "                return 'Banking'\n",
    "            elif any(keyword in name for keyword in insurance_keywords):\n",
    "                return 'Insurance'\n",
    "            elif any(keyword in name for keyword in investment_keywords):\n",
    "                return 'Investment Services'\n",
    "            return 'Other Financial'\n",
    "        \n",
    "        df['financial_sector'] = df['company'].apply(classify_sector)\n",
    "    \n",
    "    # NA value statistics\n",
    "    print(\"\\nNA values per column:\")\n",
    "    print(df.isna().sum())\n",
    "    \n",
    "    # Data shape\n",
    "    print(f\"\\nFinal data shape: {df.shape}\")\n",
    "    \n",
    "    # 6. Save Raw Data\n",
    "    # --------------------------------------------------\n",
    "    output_filename = f\"scrape_wikipedia_financial_{STAMP}.csv\"\n",
    "    outpath = CUSTOM_PATH / output_filename\n",
    "    df.to_csv(str(outpath), index=False)\n",
    "    \n",
    "    print(\"\\n=== Scraping Results ===\")\n",
    "    print(f\"Successfully saved to: {outpath}\")\n",
    "    print(f\"Contains {len(df)} financial companies records\")\n",
    "    print(f\"Financial sector distribution:\")\n",
    "    print(df['financial_sector'].value_counts() if 'financial_sector' in df.columns else \"No sector classification generated\")\n",
    "    print(\"\\nData preview:\")\n",
    "    display(df.head())\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"\\nNetwork request error: {str(e)}\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f\"\\nProcessing error occurred: {str(e)}\")\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
